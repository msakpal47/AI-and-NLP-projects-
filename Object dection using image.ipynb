{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ccf6fb-c1a3-4831-9f9c-6103d5e7a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed baggage_claim.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_baggage_claim.jpg\n",
      "Processed dining_table.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_dining_table.jpg\n",
      "Processed Hall.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_Hall.jpg\n",
      "Processed hall_view.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_hall_view.jpg\n",
      "Processed home-interior-design-ideas.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_home-interior-design-ideas.jpg\n",
      "Processed living_room.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_living_room.jpg\n",
      "Processed office-interior-designing-service.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_office-interior-designing-service.jpg\n",
      "Processed Office_view.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_Office_view.jpg\n",
      "Processed soccer.jpg and saved to C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output\\detected_soccer.jpg\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set up the directory paths for multiple images\n",
    "image_folder = r'C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\Images'  # Update this path to your folder containing images\n",
    "output_folder = r'C:\\Users\\admin\\Desktop\\Pytorch_ObjectDetection\\output'  # Update this path to where the output images will be saved\n",
    "config_path = \"yolov3.cfg\"\n",
    "weights_path = \"yolov3.weights\"\n",
    "classes_path = \"coco.names\"\n",
    "\n",
    "# Function to load YOLO output layers\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "# Function to draw bounding boxes and labels on the image\n",
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = str(classes[class_id])\n",
    "    color = COLORS[class_id % len(COLORS)]\n",
    "    cv2.rectangle(img, (x, y), (x_plus_w, y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# Load class names from file\n",
    "with open(classes_path, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Generate random colors for each class\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Load YOLO model\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Iterate through all images in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Check for image file extensions\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        \n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        Width = image.shape[1]\n",
    "        Height = image.shape[0]\n",
    "        scale = 0.00392\n",
    "\n",
    "        # Prepare the input image for the network\n",
    "        blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Get output layers and run forward pass\n",
    "        outs = net.forward(get_output_layers(net))\n",
    "\n",
    "        # Initialize lists for detected objects\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.3  # Adjust the confidence threshold as per your requirements\n",
    "        nms_threshold = 0.4  # Adjust NMS to eliminate too many overlapping boxes\n",
    "\n",
    "        # Process network outputs\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > conf_threshold:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "        # Perform non-maximum suppression to eliminate redundant boxes\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        # Draw detected objects\n",
    "        for i in indices:\n",
    "            try:\n",
    "                box = boxes[i]\n",
    "            except:\n",
    "                i = i[0]\n",
    "                box = boxes[i]\n",
    "            \n",
    "            x = box[0]\n",
    "            y = box[1]\n",
    "            w = box[2]\n",
    "            h = box[3]\n",
    "            draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x + w), round(y + h))\n",
    "\n",
    "        # Save the output image with bounding boxes\n",
    "        output_image_path = os.path.join(output_folder, f\"detected_{filename}\")\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "        print(f\"Processed {filename} and saved to {output_image_path}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8dae7-bd9f-4a03-9dda-0ae847206e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
